# Audio Deepfake

# 1. Vấn đề

- AI-synthesized tools have recently been developed with the ability to generate convincing voices

# 2. Recent method to detect AD

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled.png)

- First, each audio clip should be preprocessed and transformed into suitable audio features, such as Mel-spectrograms.
- These features are input into the detection model, which then performs the necessary
operations, such as the training process.
- The output is fed into any fully connected layer with an activation function (for a nonlinearity task) to produce a prediction probability of class 0 as fake or class 1 as real. However, there is a trade-off between accuracy and computational complexity. Further work is therefore required to improve the performance of AD detection and overcome the gaps identified in the literature.

# 3. Type of Audio Deepfake

- imitation-based
- synthetic-based
- replay based Deepfakes

## 3.1 Imitation based

A way of transforming speech (secret audio) so that
it sounds like another speech (target audio) with the primary purpose of protecting the
privacy of the secret audio

- Voices can be imitated in different ways, for example, by
using humans with similar voices who are able to imitate the original speaker
- Using algorithm: Efficient Wavelet Mask (EWM)

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%201.png)

- In particular, an original and target audio will be
recorded with similar characteristics. Then, as illustrated in Figure 2, the signal of the
original audio Figure 2a will be transformed to say the speech in the target audio in
Figure 2b using an imitation generation method that will generate a new speech, shown in
Figure 2c, which is the fake one. It is thus difficult for humans to discern between the fake
and real audio generated by this method

## 3.2 Synthetic base or Text-to-Speech

Aims to transform text into acceptable and
natural speech in real time and consists of three modules:

- text analysis model
- acoustic model
- vocoder

To generate synthetic Deepfake audio, 2 crucial steps should be followed

- First, clean and structured raw audio should be collected, with a transcript text of the audio speech
- Using model to train such as: Tactoran 2, Deep Voice 3, FastSpeech 2

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%202.png)

In the synthetic technique, the transcript text with the voice of the target speaker will be fed into the
generation model. The text analysis module then processes the incoming text and converts
it into linguistic characteristics. Then, the acoustic module extracts the parameters of the
target speaker from the dataset depending on the linguistic features generated from the
text analysis module. Last, the vocoder will learn to create speech waveforms based on the accoustic feature parameters, and the final audio file will be generated, which includes the synthetic
fake audio in a waveform format

## 3.3 Replay based

Replay-based Deepfakes are a type of malicious work that aims to replay a recording
of the target speaker’s voice [14]. There are two types: far-field detection and cut-andpaste detection. In far-field detection, a microphone recording of the victim recording is
played as a test segment on a telephone handset with a loudspeaker [15]. Meanwhile, cutting and pasting involves faking the sentence required by a text-dependent system [15].
This article will focus on Deepfake methods spoofing real voices rather than approaches
that use edited recordings. This review will thus cover the detection methods used to
identify synthetic and imitation Deepfakes, and replay-based attacks will be cons

****************Focus on 3.1 and 3.2****************

# 4. Fake audio detection methods

Types: ML and DL methods

## 4.1 ML

- Xây dựng fake audio dataset based on imitation method bằng cách extract entropy features của real và fake audio. Sử dụng H-Voice dataset + Model Logistic Regression, Các model khác như Q-SVM, KNN, STLT, ….

⇒ ML cần extract feature thủ công và tiền xử lý chuyên sâu ⇒ Mất tg

## 4.2 DL

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%203.png)

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%204.png)

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%205.png)

# 5. Fake Audio Detection Datasets

H-Voice: base on imitation vs synthetic voices speaking English, Spanish, Portuguese, French, Tagalog

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%206.png)

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%207.png)

Hvoice: [https://data.mendeley.com/datasets/k47yd3m28w/4](https://data.mendeley.com/datasets/k47yd3m28w/4)

Fake oR Real(FoR): [https://bil.eecs.yorku.ca/datasets](https://bil.eecs.yorku.ca/datasets/)

# 6. Summary

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%208.png)

![Untitled](Audio%20Deepfake%208809b08c8da342a0b0c85207cd0be260/Untitled%209.png)

# 7. Tóm tắt

**3 loại AD nhưng tập trung vào 2 loại là:**

- imitation (voice + voice → voice)
- synthetic (text + voice → voice)

Dạng đầu khá giống Neural style transfer → Xử lý data 1 loại

Dạng 2 thì kết hợp cả text-to-speech → Xử lý data 2 loại

******Phương pháp để detect:******

- Đơn giản nhất là dùng ML- Logistic
- DL- CNN bth..

****Có nhiều loại dataset nhưng chủ yếu là English, các dataset chủ yếu là dạng synthetic fake, có tập H-voice là có cả synthetic lẫn imitation****

# 8 Một số link tài liệu

## Code:

[1 - https://www.youtube.com/watch?v=_CtMdrkXxJA](https://www.youtube.com/watch?v=_CtMdrkXxJA)

[2- Series cho audio music processing](https://www.youtube.com/watch?v=gp2wZqDoJ1Y&list=PL-wATfeyAMNoirN4idjev6aRu8ISZYVWm)